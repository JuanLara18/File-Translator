"""
Translation Script

This script reads Excel (.xlsx) or Stata (.dta) files, translates specified columns from German
to English using the OpenAI API, and writes out a new file with all original data plus
additional columns containing English translations.

Usage:
    python enhanced_translation.py --input input_file.[xlsx|dta] --column German_Text [--output output_file.[xlsx|dta]] [--batch_size 10]

If the output file is not specified, it will be automatically generated by appending '_translated'
to the input file's name.
"""

import os
import sys
import argparse
import logging
import datetime
from typing import List, Dict, Any, Union, Tuple
from dotenv import load_dotenv
import pandas as pd
from tqdm import tqdm
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import numpy as np
from threading import Lock


# -----------------------
# Configuration and Setup
# -----------------------

# Set up logging
script_dir = os.path.dirname(os.path.abspath(__file__))
logging.basicConfig(
    filename=os.path.join(script_dir, 'translation.log'),
    filemode='a',
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Load environment variables from .env file
load_dotenv("OPENAI_API_KEY.env")
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    logging.error("OpenAI API key not found in environment variables.")
    raise ValueError("OpenAI API key not found in environment variables. Please set it in your .env file.")

# Initialize OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)

# Global constants
MODEL_NAME = 'gpt-3.5-turbo'

# -----------------------
# Functions
# -----------------------

def batch_translate_texts(texts: List[str], translation_cache: Dict[str, str] = None) -> Dict[str, str]:
    """
    Translates a batch of texts in parallel using ThreadPoolExecutor.
    
    Args:
        texts: List of unique texts to translate
        translation_cache: Optional cache dictionary for storing translations
    
    Returns:
        Dictionary with translations
    """
    if translation_cache is None:
        translation_cache = {}
    
    cache_lock = Lock()
    texts_to_translate = [text for text in texts if text not in translation_cache or not translation_cache[text]]
    
    if not texts_to_translate:
        return translation_cache
    
    def translate_single(text: str) -> tuple[str, str]:
        if not isinstance(text, str) or not text.strip():
            return text, text
        
        translated = translate_text(text)
        with cache_lock:
            translation_cache[text] = translated
        return text, translated

    with ThreadPoolExecutor(max_workers=5) as executor:
        list(executor.map(translate_single, texts_to_translate))
    
    return translation_cache

def extract_translation(response_text: str) -> tuple[str, bool]:
    """
    Extracts and validates translation from a response.
    Returns the translation and a boolean indicating if it's valid.
    
    :param response_text: The response text to validate
    :return: Tuple of (translation, is_valid_format)
    """
    try:
        # Si el texto está vacío o no es string, no es válido
        if not isinstance(response_text, str) or not response_text.strip():
            return response_text, False
            
        # Limpiar el texto de elementos comunes no deseados
        cleaned_text = (response_text.strip()
                       .replace('"', '')
                       .replace("'", "")
                       .replace(" translates to ", "")
                       .replace(" means ", "")
                       .replace(" in English", "")
                       .replace("Translation: ", ""))
        
        # Validaciones específicas para asegurar que es una traducción válida
        invalid_markers = [
            "means",
            "translates",
            "translation",
            "in English",
            "[original text]",
            "(German)",
            "German:",
            "English:",
            "=>",
            "->",
        ]
        
        # Si contiene marcadores de explicación, no es una traducción limpia
        if any(marker in cleaned_text.lower() for marker in invalid_markers):
            return response_text, False
            
        # Verificar que no sea igual al texto original si es una palabra común
        common_german_words = {"ja", "nein", "und", "oder", "der", "die", "das"}
        if cleaned_text.lower() in common_german_words:
            return response_text, False
            
        return cleaned_text, True
        
    except Exception as e:
        logging.error(f"Error extracting translation: {e}")
        return response_text, False

def create_translation_cache(df: pd.DataFrame, column: str) -> dict:
    """
    Creates a translation cache dictionary from unique values in the specified column.
    
    Args:
        df: Input DataFrame
        column: Column name containing texts to translate
    
    Returns:
        Dictionary with unique texts as keys and None as initial values
    """
    return {text: None for text in df[column].dropna().unique() if isinstance(text, str)}

def translate_text(text: str, translation_cache: dict = None) -> str:
    """
    Translates text from German to English, optimized for machine error descriptions.
    Uses caching to avoid redundant translations.
    
    :param text: A string in German to translate
    :param translation_cache: Cache of previous translations
    :return: The English translation as a string
    """
    if not isinstance(text, str) or not text.strip():
        return text

    system_message = """You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules strictly:

1. Translate from German to English precisely and technically
2. Use consistent technical terminology
3. IMPORTANT: Only use the word "Error" if the German text contains "Fehler" or "Störung". Do not add the word "Error" if it's not in the original text
4. Keep all codes, numbers, and technical identifiers exactly as they appear (e.g., CC31 should stay CC31, not "Error CC31")
5. Maintain exact punctuation from the original text
6. Do not add any explanations or alternatives
7. Do not modify technical terms in brackets or parentheses
8. Preserve all variable names and placeholders exactly as they appear
9. NEVER add words that are not in the original text!

Example:
Input: "Fehler E123: Motorüberhitzung"
Output: Error E123: Motor overheating

Do not add any additional text, explanations, or the word 'Error' unless 'Fehler' or 'Störung' is present in the original text. Respond ONLY with the direct translation."""

    try:
        # Check cache first if provided
        if translation_cache is not None and text in translation_cache:
            return translation_cache[text]

        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": f"Translate: {text}"}
            ],
            temperature=0.1,
            max_tokens=1000  # Reduced as error messages are typically short
        )

        translated_text = response.choices[0].message.content.strip()
        
        # Clean the translation while preserving technical elements
        translated_text = (translated_text
                         .replace('"', '')
                         .replace("'", "")
                         .replace(" translates to ", "")
                         .replace(" means ", "")
                         .replace(" in English", "")
                         .replace("Translation: ", "")
                         .strip())

        # Update cache if provided
        if translation_cache is not None:
            translation_cache[text] = translated_text

        logging.info(f"Translated: {text} → {translated_text}")
        return translated_text

    except Exception as e:
        logging.error(f"Translation error for '{text}': {str(e)}")
        return text

def process_files(input_file: str, output_file: str, translate_col: str, 
                new_col_name: str = "Translation", batch_size: int = 10):
    """
    Optimized version of process_files that uses parallel processing,
    better unique value handling, and robust translation validation.
    """
    try:
        # Determine file type from extension
        file_extension = os.path.splitext(input_file)[1].lower()
        
        # Read file based on type
        if file_extension in ['.xlsx', '.xls']:
            df = pd.read_excel(input_file)
            stata_meta = None
            logging.info(f"Loaded Excel file: {input_file} with {len(df)} rows.")
        elif file_extension == '.dta':
            try:
                # Read Stata file with metadata
                df = pd.read_stata(input_file, convert_categoricals=False)
                stata_meta = {
                    'value_labels': df.value_labels() if hasattr(df, 'value_labels') else {},
                    'variable_labels': df.variable_labels() if hasattr(df, 'variable_labels') else {},
                    'formats': {col: df[col].dtype for col in df.columns},
                    'value_label_dict': {}
                }
                
                for col in df.columns:
                    if hasattr(df[col], 'cat') and hasattr(df[col].cat, 'categories'):
                        stata_meta['value_label_dict'][col] = dict(zip(
                            df[col].cat.categories,
                            df[col].cat.categories
                        ))
                
                logging.info(f"Loaded Stata file: {input_file} with {len(df)} rows and metadata.")
            except Exception as e:
                logging.warning(f"Could not load complete Stata metadata: {e}")
                df = pd.read_stata(input_file)
                stata_meta = None
                logging.info(f"Loaded Stata file without metadata: {input_file} with {len(df)} rows.")
        else:
            raise ValueError(f"Unsupported file type: {file_extension}")

        # Validate column
        if translate_col not in df.columns:
            try:
                col_index = ord(translate_col.upper()) - ord('A')
                if 0 <= col_index < len(df.columns):
                    translate_col = df.columns[col_index]
                else:
                    raise ValueError(f"Column letter '{translate_col}' is out of range")
            except Exception as e:
                logging.error(f"Invalid column identifier '{translate_col}': {e}")
                raise ValueError(f"Invalid column identifier '{translate_col}'.")

        # Create translation cache from unique values
        translation_cache = create_translation_cache(df, translate_col)
        logging.info(f"Created translation cache with {len(translation_cache)} unique texts.")

        # Process texts in batches
        unique_texts = list(translation_cache.keys())
        processed_translations = {}
        invalid_translations = []

        for i in range(0, len(unique_texts), batch_size):
            batch = unique_texts[i:i + batch_size]
            
            # Get translations for the batch
            batch_translations = batch_translate_texts(batch, processed_translations)
            
            # Validate each translation
            for original, translated in batch_translations.items():
                cleaned_translation, is_valid = extract_translation(translated)
                if is_valid:
                    processed_translations[original] = cleaned_translation
                else:
                    invalid_translations.append(original)
                    # Retry invalid translations individually
                    single_translation = translate_text(original)
                    retry_translation, retry_valid = extract_translation(single_translation)
                    if retry_valid:
                        processed_translations[original] = retry_translation
                    else:
                        processed_translations[original] = original  # Keep original if translation fails
                        logging.warning(f"Translation failed for text: {original}")

        # Apply translations using the processed translations dictionary
        df[new_col_name] = df[translate_col].map(processed_translations)

        # Save file based on type
        if file_extension in ['.xlsx', '.xls']:
            df.to_excel(output_file, index=False)
            logging.info(f"Saved translated Excel file to: {output_file}")
        else:  # .dta
            try:
                if stata_meta:
                    if 'variable_labels' in stata_meta:
                        original_label = stata_meta['variable_labels'].get(translate_col, translate_col)
                        stata_meta['variable_labels'][new_col_name] = f"English translation of: {original_label}"
                    
                    df.to_stata(
                        output_file,
                        write_index=False,
                        variable_labels=stata_meta['variable_labels'],
                        value_labels=stata_meta['value_labels'],
                        version=118
                    )
                else:
                    df.to_stata(output_file, write_index=False, version=118)
                logging.info(f"Saved translated Stata file to: {output_file}")
            except Exception as e:
                logging.error(f"Error saving Stata file: {e}")
                df.to_stata(output_file, write_index=False, version=118)
                logging.info(f"Saved translated Stata file without metadata to: {output_file}")

        # Log translation statistics
        total_texts = len(df)
        unique_text_count = len(unique_texts)
        saved_calls = total_texts - unique_text_count
        invalid_count = len(invalid_translations)
        
        logging.info("Translation statistics:")
        logging.info(f"Total texts processed: {total_texts}")
        logging.info(f"Unique texts translated: {unique_text_count}")
        logging.info(f"API calls saved through caching: {saved_calls}")
        logging.info(f"Invalid translations requiring retry: {invalid_count}")
        
        return df, processed_translations

    except Exception as e:
        logging.error(f"Error processing file: {e}")
        raise

def generate_output_filename(input_file: str) -> str:
    """
    Generates an output filename by appending '_translated' before the file extension.
    
    :param input_file: The input file name.
    :return: The generated output file name.
    """
    base, ext = os.path.splitext(input_file)
    return f"{base}_translated{ext}"

def parse_args():
    """
    Parses command-line arguments.
    """
    parser = argparse.ArgumentParser(
        description="Translate a specified column in the file from German to English."
    )
    parser.add_argument(
        "--input",
        required=True,
        help="Path to the input file."
    )
    parser.add_argument(
        "--output",
        help="Path to the output file. If not provided, the script will auto-generate one."
    )
    parser.add_argument(
        "--column",
        required=True,
        help="Column to translate (can be a column name or a letter, e.g., 'B')."
    )
    parser.add_argument(
        "--new_col",
        default="Translation",
        help="Name of the new column to hold the English translation. Default is 'Translation'."
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=10,
        help="Number of rows to process at a time. Default is 10."
    )
    return parser.parse_args()

# -----------------------
# Main Execution
# -----------------------

if __name__ == "__main__":
    args = parse_args()

    # Determine the output file name if not specified
    output_file = args.output if args.output else generate_output_filename(args.input)

    start_time = datetime.datetime.now()
    logging.info("Starting translation process.") 

    process_files(  # Changed from process_excel
        input_file=args.input,
        output_file=output_file,
        translate_col=args.column,
        new_col_name=args.new_col,
        batch_size=args.batch_size
    )

    end_time = datetime.datetime.now()
    elapsed_time = (end_time - start_time).total_seconds()
    print(f"Translation completed in {elapsed_time:.2f} seconds. Output saved to {output_file}.")
    logging.info(f"Translation process finished in {elapsed_time:.2f} seconds.")